{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T22:53:31.468082Z",
     "iopub.status.busy": "2024-11-24T22:53:31.467054Z",
     "iopub.status.idle": "2024-11-24T22:53:45.513978Z",
     "shell.execute_reply": "2024-11-24T22:53:45.511373Z",
     "shell.execute_reply.started": "2024-11-24T22:53:31.468025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ninadaithal/imagesoasis?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.23G/1.23G [00:50<00:00, 26.0MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\rohan\\.cache\\kagglehub\\datasets\\ninadaithal\\imagesoasis\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ninadaithal/imagesoasis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:11.015901Z",
     "iopub.status.busy": "2024-11-24T23:27:11.015303Z",
     "iopub.status.idle": "2024-11-24T23:27:11.025385Z",
     "shell.execute_reply": "2024-11-24T23:27:11.023883Z",
     "shell.execute_reply.started": "2024-11-24T23:27:11.015854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:13.640557Z",
     "iopub.status.busy": "2024-11-24T23:27:13.640118Z",
     "iopub.status.idle": "2024-11-24T23:27:13.853051Z",
     "shell.execute_reply": "2024-11-24T23:27:13.851964Z",
     "shell.execute_reply.started": "2024-11-24T23:27:13.640520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86432</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86433</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86434</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86435</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86436</th>\n",
       "      <td>C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "0      C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      0\n",
       "1      C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      0\n",
       "2      C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      0\n",
       "3      C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      0\n",
       "4      C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      0\n",
       "...                                                  ...    ...\n",
       "86432  C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      3\n",
       "86433  C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      3\n",
       "86434  C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      3\n",
       "86435  C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      3\n",
       "86436  C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archi...      3\n",
       "\n",
       "[86437 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create your DataFrame\n",
    "images = []\n",
    "labels = []\n",
    "for subfolder in tqdm(os.listdir(r'C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archive')):\n",
    "    subfolder_path = os.path.join(r'C:\\Users\\rohan\\Desktop\\184a\\AD-Detection\\archive', subfolder)\n",
    "    label = 0\n",
    "    for folder in os.listdir(subfolder_path):\n",
    "        subfolder_path2 = os.path.join(subfolder_path, folder)\n",
    "        for image_filename in os.listdir(subfolder_path2):\n",
    "            image_path = os.path.join(subfolder_path2, image_filename)\n",
    "            images.append(image_path)\n",
    "            labels.append(label)\n",
    "        label += 1\n",
    "\n",
    "df = pd.DataFrame({'image': images, 'label': labels})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:19.494823Z",
     "iopub.status.busy": "2024-11-24T23:27:19.494392Z",
     "iopub.status.idle": "2024-11-24T23:27:19.533512Z",
     "shell.execute_reply": "2024-11-24T23:27:19.532353Z",
     "shell.execute_reply.started": "2024-11-24T23:27:19.494779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:22.626181Z",
     "iopub.status.busy": "2024-11-24T23:27:22.625774Z",
     "iopub.status.idle": "2024-11-24T23:27:22.635274Z",
     "shell.execute_reply": "2024-11-24T23:27:22.634067Z",
     "shell.execute_reply.started": "2024-11-24T23:27:22.626144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ADDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get image path and label\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((176, 176)), # Resize all images to 176x176\n",
    "    transforms.ToTensor(),        # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize with ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:28.879342Z",
     "iopub.status.busy": "2024-11-24T23:27:28.878932Z",
     "iopub.status.idle": "2024-11-24T23:27:29.996737Z",
     "shell.execute_reply": "2024-11-24T23:27:29.995415Z",
     "shell.execute_reply.started": "2024-11-24T23:27:28.879306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataLoader:\n",
      "torch.Size([16, 3, 176, 176])\n",
      "tensor([2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "Testing DataLoader:\n",
      "torch.Size([16, 3, 176, 176])\n",
      "tensor([2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create Datasets for training and testing\n",
    "train_dataset = ADDataset(dataframe=train_df, transform=transform)\n",
    "test_dataset = ADDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Test the DataLoader\n",
    "print(\"Training DataLoader:\")\n",
    "for images, labels in train_dataloader:\n",
    "    print(images.shape)  # Should be [batch_size, 3, 176, 176]\n",
    "    print(labels)        # Corresponding labels\n",
    "    break\n",
    "\n",
    "print(\"Testing DataLoader:\")\n",
    "for images, labels in test_dataloader:\n",
    "    print(images.shape)  # Should be [batch_size, 3, 176, 176]\n",
    "    print(labels)        # Corresponding labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:41.695517Z",
     "iopub.status.busy": "2024-11-24T23:27:41.695029Z",
     "iopub.status.idle": "2024-11-24T23:27:41.710046Z",
     "shell.execute_reply": "2024-11-24T23:27:41.708717Z",
     "shell.execute_reply.started": "2024-11-24T23:27:41.695474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FeatureExtractionBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.max_pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ADCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.25):\n",
    "        super(ADCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Feature Extraction Blocks\n",
    "        self.block1 = FeatureExtractionBlock(16, 32)  # Output: 32 channels\n",
    "        self.block2 = FeatureExtractionBlock(32, 64)  # Output: 64 channels\n",
    "        self.block3 = FeatureExtractionBlock(64, 128)  # Output: 128 channels\n",
    "        self.block4 = FeatureExtractionBlock(128, 256)  # Output: 256 channels\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64) \n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "        \n",
    "        # Softmax layer is applied in forward\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:45.128724Z",
     "iopub.status.busy": "2024-11-24T23:27:45.128328Z",
     "iopub.status.idle": "2024-11-24T23:27:45.187018Z",
     "shell.execute_reply": "2024-11-24T23:27:45.185579Z",
     "shell.execute_reply.started": "2024-11-24T23:27:45.128686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = ADCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T23:27:47.463636Z",
     "iopub.status.busy": "2024-11-24T23:27:47.463255Z",
     "iopub.status.idle": "2024-11-24T23:27:58.827995Z",
     "shell.execute_reply": "2024-11-24T23:27:58.826162Z",
     "shell.execute_reply.started": "2024-11-24T23:27:47.463601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 176, 176]) torch.Size([16])\n",
      "Epoch [1/50], Loss: 0.8516, Accuracy: 77.29%\n",
      "Epoch [2/50], Loss: 0.3140, Accuracy: 87.46%\n",
      "Epoch [3/50], Loss: 0.1346, Accuracy: 95.06%\n",
      "Epoch [4/50], Loss: 0.0755, Accuracy: 97.44%\n",
      "Epoch [5/50], Loss: 0.0529, Accuracy: 98.22%\n",
      "Epoch [6/50], Loss: 0.0406, Accuracy: 98.68%\n",
      "Epoch [7/50], Loss: 0.0336, Accuracy: 98.88%\n",
      "Epoch [8/50], Loss: 0.0287, Accuracy: 99.12%\n",
      "Epoch [9/50], Loss: 0.0254, Accuracy: 99.24%\n",
      "Epoch [10/50], Loss: 0.0245, Accuracy: 99.27%\n",
      "Epoch [11/50], Loss: 0.0232, Accuracy: 99.34%\n",
      "Epoch [12/50], Loss: 0.0229, Accuracy: 99.43%\n",
      "Epoch [13/50], Loss: 0.0191, Accuracy: 99.46%\n",
      "Epoch [14/50], Loss: 0.0180, Accuracy: 99.51%\n",
      "Epoch [15/50], Loss: 0.0176, Accuracy: 99.56%\n",
      "Epoch [16/50], Loss: 0.0179, Accuracy: 99.55%\n",
      "Epoch [17/50], Loss: 0.0164, Accuracy: 99.56%\n",
      "Epoch [18/50], Loss: 0.0155, Accuracy: 99.58%\n",
      "Epoch [19/50], Loss: 0.0145, Accuracy: 99.62%\n",
      "Epoch [20/50], Loss: 0.0176, Accuracy: 99.70%\n",
      "Epoch [21/50], Loss: 0.0138, Accuracy: 99.66%\n",
      "Epoch [22/50], Loss: 0.0127, Accuracy: 99.69%\n",
      "Epoch [23/50], Loss: 0.0141, Accuracy: 99.68%\n",
      "Epoch [24/50], Loss: 0.0138, Accuracy: 99.69%\n",
      "Epoch [25/50], Loss: 0.0128, Accuracy: 99.74%\n",
      "Epoch [26/50], Loss: 0.0133, Accuracy: 99.70%\n",
      "Epoch [27/50], Loss: 0.0131, Accuracy: 99.74%\n",
      "Epoch [28/50], Loss: 0.0137, Accuracy: 99.71%\n",
      "Epoch [29/50], Loss: 0.0105, Accuracy: 99.78%\n",
      "Epoch [30/50], Loss: 0.0135, Accuracy: 99.75%\n",
      "Epoch [31/50], Loss: 0.0142, Accuracy: 99.71%\n",
      "Epoch [32/50], Loss: 0.0127, Accuracy: 99.76%\n",
      "Epoch [33/50], Loss: 0.0137, Accuracy: 99.75%\n",
      "Epoch [34/50], Loss: 0.0145, Accuracy: 99.75%\n",
      "Epoch [35/50], Loss: 0.0161, Accuracy: 99.77%\n",
      "Epoch [36/50], Loss: 0.0134, Accuracy: 99.80%\n",
      "Epoch [37/50], Loss: 0.0118, Accuracy: 99.80%\n",
      "Epoch [38/50], Loss: 0.0144, Accuracy: 99.78%\n",
      "Epoch [39/50], Loss: 0.0129, Accuracy: 99.82%\n",
      "Epoch [40/50], Loss: 0.0135, Accuracy: 99.81%\n",
      "Epoch [41/50], Loss: 0.0152, Accuracy: 99.78%\n",
      "Epoch [42/50], Loss: 0.0160, Accuracy: 99.81%\n",
      "Epoch [43/50], Loss: 0.0133, Accuracy: 99.82%\n",
      "Epoch [44/50], Loss: 0.0140, Accuracy: 99.80%\n",
      "Epoch [45/50], Loss: 0.0155, Accuracy: 99.80%\n",
      "Epoch [46/50], Loss: 0.0156, Accuracy: 99.80%\n",
      "Epoch [47/50], Loss: 0.0170, Accuracy: 99.80%\n",
      "Epoch [48/50], Loss: 0.0158, Accuracy: 99.82%\n",
      "Epoch [49/50], Loss: 0.0155, Accuracy: 99.81%\n",
      "Epoch [50/50], Loss: 0.0170, Accuracy: 99.82%\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for inputs, labels in train_dataloader:\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=50, learning_rate=0.001, device='cuda'):\n",
    "    # Move model to the selected device (GPU or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize RMSprop optimizer\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Loss function (CrossEntropy for classification)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to the selected device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass (backpropagation)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print stats for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "        # Optional: You can validate your model here by running the validation loop if you have a validation set.\n",
    "        # validate_model(model, val_loader)  # Add your validation code here\n",
    "     \n",
    "    print('Training Finished!')\n",
    "\n",
    "\n",
    "train_model(model, train_dataloader , num_epochs=50, learning_rate=0.001, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the Test Set\n",
      "-----------\n",
      "[[ 1000     0     0     0]\n",
      " [    0    98     0     0]\n",
      " [    0     0 13442     3]\n",
      " [    0     0     1  2744]]\n",
      "Precision of the Model :\t0.9998\n",
      "Recall of the Model    :\t0.9998\n",
      "F1 Score of the Model  :\t0.9998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    y_pred_list = []\n",
    "    y_target_list = []\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No gradient calculations needed\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move data to the selected device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            _, y_pred = torch.max(outputs, 1)  # Predicted labels\n",
    "            \n",
    "            y_pred_list.append(y_pred.cpu().numpy())  # Move to CPU for metrics\n",
    "            y_target_list.append(labels.cpu().numpy())  # Move to CPU for metrics\n",
    "\n",
    "    # Flatten the predictions and targets\n",
    "    y_pred_list = list(itertools.chain.from_iterable(y_pred_list))\n",
    "    y_target_list = list(itertools.chain.from_iterable(y_target_list))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_target_list, y_pred_list)\n",
    "    print(\"Confusion Matrix of the Test Set\")\n",
    "    print(\"-----------\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_target_list, y_pred_list, average='weighted')\n",
    "    recall = recall_score(y_target_list, y_pred_list, average='weighted')\n",
    "    f1 = f1_score(y_target_list, y_pred_list, average='weighted')\n",
    "\n",
    "    print(f\"Precision of the Model :\\t{precision:.4f}\")\n",
    "    print(f\"Recall of the Model    :\\t{recall:.4f}\")\n",
    "    print(f\"F1 Score of the Model  :\\t{f1:.4f}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "evaluate_model(model, test_dataloader, device='cuda')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3419493,
     "sourceId": 5962731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
